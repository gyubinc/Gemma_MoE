# Qwen-MoE v2.0 API Documentation

## ğŸ“š Core Components

### DomainManager

ë„ë©”ì¸ë³„ ì„¤ì •ì„ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

```python
from src.configs import domain_manager

# ì‚¬ìš© ê°€ëŠ¥í•œ ë„ë©”ì¸ í™•ì¸
domains = domain_manager.get_available_domains()
# ['medical', 'law', 'math', 'code']

# ë„ë©”ì¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
config = domain_manager.get_domain('medical')

# ë°ì´í„° ê°€ìš©ì„± í™•ì¸
availability = domain_manager.check_data_availability('medical')

# í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…
prompt = domain_manager.format_prompt('medical', question="...", options=["A", "B", "C", "D"])

# ì‘ë‹µ í¬ë§·íŒ…
response = domain_manager.format_response('medical', correct_option=0)
```

#### Methods

- `get_domain(domain_name: str) -> DomainConfig`: ë„ë©”ì¸ ì„¤ì • ë°˜í™˜
- `get_available_domains() -> List[str]`: ì‚¬ìš© ê°€ëŠ¥í•œ ë„ë©”ì¸ ëª©ë¡
- `check_data_availability(domain_name: str = None) -> Dict[str, bool]`: ë°ì´í„° ê°€ìš©ì„± í™•ì¸
- `get_domain_stats(domain_name: str) -> Dict[str, Any]`: ë„ë©”ì¸ í†µê³„ ì •ë³´
- `format_prompt(domain_name: str, **kwargs) -> str`: í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…
- `format_response(domain_name: str, **kwargs) -> str`: ì‘ë‹µ í¬ë§·íŒ…

### UnifiedDataset

ëª¨ë“  ë„ë©”ì¸ì„ ì§€ì›í•˜ëŠ” í†µí•© ë°ì´í„°ì…‹ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

```python
from src.core import UnifiedDataset

# ë°ì´í„°ì…‹ ìƒì„±
dataset = UnifiedDataset(
    tokenizer=tokenizer,
    domain='medical',
    split='train',
    max_samples=1000,
    max_length=512
)

# ë°ì´í„°ì…‹ í¬ê¸°
print(len(dataset))

# ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°
sample = dataset[0]
# {'input_ids': tensor(...), 'attention_mask': tensor(...), 'labels': tensor(...)}
```

#### Parameters

- `tokenizer`: HuggingFace í† í¬ë‚˜ì´ì €
- `domain`: ë„ë©”ì¸ ì´ë¦„ ('medical', 'law', 'math', 'code')
- `split`: ë°ì´í„° ë¶„í•  ('train', 'validation', 'test')
- `max_samples`: ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ (Noneì´ë©´ ì „ì²´ ì‚¬ìš©)
- `max_length`: ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´

### UnifiedTrainer

ëª¨ë“  ë„ë©”ì¸ì„ ì§€ì›í•˜ëŠ” í†µí•© í›ˆë ¨ê¸° í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

```python
from src.core import UnifiedTrainer

# í›ˆë ¨ê¸° ìƒì„±
trainer = UnifiedTrainer(
    domain='medical',
    output_dir='domain_models',
    device='cuda:0'
)

# í›ˆë ¨ ì„¤ì •
trainer.setup_training(max_samples=1000)

# í›ˆë ¨ ì‹¤í–‰
results = trainer.train()

# ì •ë¦¬
trainer.cleanup()
```

#### Methods

- `setup_training(max_samples: int = None)`: í›ˆë ¨ ì„¤ì •
- `train() -> Dict[str, Any]`: í›ˆë ¨ ì‹¤í–‰
- `evaluate(adapter_path: str = None) -> Dict[str, Any]`: í‰ê°€ ì‹¤í–‰
- `cleanup()`: ë¦¬ì†ŒìŠ¤ ì •ë¦¬

### UnifiedEvaluator

ëª¨ë“  ë„ë©”ì¸ì„ ì§€ì›í•˜ëŠ” í†µí•© í‰ê°€ê¸° í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

```python
from src.core import UnifiedEvaluator

# í‰ê°€ê¸° ìƒì„±
evaluator = UnifiedEvaluator(device='cuda:0')

# ëª¨ë¸ ë¡œë”©
evaluator.load_model(adapter_path='domain_models/medical/final_adapter')

# ë‹¨ì¼ ë„ë©”ì¸ í‰ê°€
results = evaluator.evaluate_domain('medical', max_samples=1000)

# ëª¨ë“  ë„ë©”ì¸ í‰ê°€
results = evaluator.evaluate_all_domains()

# ì •ë¦¬
evaluator.cleanup()
```

#### Methods

- `load_model(adapter_path: str = None)`: ëª¨ë¸ ë¡œë”©
- `evaluate_domain(domain: str, max_samples: int = 1000, split: str = 'test') -> Dict[str, Any]`: ë‹¨ì¼ ë„ë©”ì¸ í‰ê°€
- `evaluate_all_domains(domains: List[str] = None, max_samples: int = 1000) -> Dict[str, Any]`: ëª¨ë“  ë„ë©”ì¸ í‰ê°€
- `cleanup()`: ë¦¬ì†ŒìŠ¤ ì •ë¦¬

### ModelManager

ëª¨ë¸ ë¡œë”©ê³¼ ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

```python
from src.core import model_manager

# ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë”©
model, tokenizer = model_manager.load_base_model()

# ì–´ëŒ‘í„°ì™€ í•¨ê»˜ ëª¨ë¸ ë¡œë”©
model, tokenizer = model_manager.load_model_with_adapter('path/to/adapter')

# í…ìŠ¤íŠ¸ ìƒì„±
text = model_manager.generate("Hello, world!", max_new_tokens=50)

# ì–´ëŒ‘í„° ì €ì¥
model_manager.save_adapter('path/to/save')

# ë©”ëª¨ë¦¬ ì •ë¦¬
model_manager.clear_memory()
```

#### Methods

- `load_base_model() -> Tuple[AutoModelForCausalLM, AutoTokenizer]`: ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë”©
- `load_model_with_adapter(adapter_path: str) -> Tuple[PeftModel, AutoTokenizer]`: ì–´ëŒ‘í„°ì™€ í•¨ê»˜ ëª¨ë¸ ë¡œë”©
- `generate(prompt: str, max_new_tokens: int = 50, **kwargs) -> str`: í…ìŠ¤íŠ¸ ìƒì„±
- `save_adapter(adapter_path: str)`: ì–´ëŒ‘í„° ì €ì¥
- `clear_memory()`: ë©”ëª¨ë¦¬ ì •ë¦¬

## ğŸ”§ Utility Functions

### Memory Management

```python
from src.utils import (
    print_gpu_memory_summary,
    print_system_memory_summary,
    clear_gpu_memory,
    get_optimal_batch_size
)

# GPU ë©”ëª¨ë¦¬ ìš”ì•½ ì¶œë ¥
print_gpu_memory_summary("After model loading")

# ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ìš”ì•½ ì¶œë ¥
print_system_memory_summary()

# GPU ë©”ëª¨ë¦¬ ì •ë¦¬
clear_gpu_memory()

# ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚°
batch_sizes = get_optimal_batch_size(model_size_gb=4.0, gpu_memory_gb=46.0)
```

### Data Utilities

```python
from src.utils import (
    check_data_availability,
    analyze_dataset_samples,
    get_domain_statistics,
    validate_environment
)

# ë°ì´í„° ê°€ìš©ì„± í™•ì¸
availability = check_data_availability(['medical', 'law'])

# ë°ì´í„°ì…‹ ìƒ˜í”Œ ë¶„ì„
analysis = analyze_dataset_samples(['medical'], max_samples=3)

# ë„ë©”ì¸ í†µê³„ ê°€ì ¸ì˜¤ê¸°
stats = get_domain_statistics('medical')

# í™˜ê²½ ê²€ì¦
is_valid = validate_environment()
```

## ğŸš€ Convenience Functions

### Training

```python
from src.core import train_domain

# ë„ë©”ì¸ í›ˆë ¨ (í¸ì˜ í•¨ìˆ˜)
results = train_domain(
    domain='medical',
    max_samples=1000,
    output_dir='domain_models'
)
```

### Evaluation

```python
from src.core import evaluate_domain, evaluate_all_domains

# ë‹¨ì¼ ë„ë©”ì¸ í‰ê°€ (í¸ì˜ í•¨ìˆ˜)
results = evaluate_domain(
    domain='medical',
    adapter_path='domain_models/medical/final_adapter',
    max_samples=1000
)

# ëª¨ë“  ë„ë©”ì¸ í‰ê°€ (í¸ì˜ í•¨ìˆ˜)
results = evaluate_all_domains(
    adapter_path=None,  # ë² ì´ìŠ¤ ëª¨ë¸ ì‚¬ìš©
    max_samples=1000
)
```

### Dataset Creation

```python
from src.core import create_datasets

# ë„ë©”ì¸ë³„ ë°ì´í„°ì…‹ ìƒì„±
datasets = create_datasets(
    domain='medical',
    tokenizer=tokenizer,
    max_samples=1000
)

# datasets = {
#     'train': UnifiedDataset(...),
#     'validation': UnifiedDataset(...) or 'test': UnifiedDataset(...)
# }
```

## ğŸ“Š Data Structures

### DomainConfig

```python
@dataclass
class DomainConfig:
    name: str                    # ë„ë©”ì¸ ì´ë¦„
    data_path: str              # ë°ì´í„° ê²½ë¡œ
    train_file: str             # í›ˆë ¨ íŒŒì¼ëª…
    validation_file: str        # ê²€ì¦ íŒŒì¼ëª…
    test_file: str              # í…ŒìŠ¤íŠ¸ íŒŒì¼ëª…
    instruction_template: str   # ì§€ì‹œì‚¬í•­ í…œí”Œë¦¿
    response_format: str        # ì‘ë‹µ í˜•ì‹
    evaluation_type: str        # í‰ê°€ ìœ í˜•
    max_length: int = 512       # ìµœëŒ€ ê¸¸ì´
    num_choices: int = 4        # ì„ íƒì§€ ìˆ˜
```

### Training Results

```python
{
    "domain": "medical",
    "train_loss": 0.1234,
    "train_runtime": 3600.0,
    "train_samples_per_second": 0.5,
    "adapter_path": "domain_models/medical/final_adapter"
}
```

### Evaluation Results

```python
{
    "domain": "medical",
    "accuracy": 0.7567,
    "total_samples": 1000,
    "correct_predictions": 757,
    "predictions": ["A", "B", "C", ...],
    "references": ["A", "B", "C", ...],
    "evaluation_type": "multiple_choice"
}
```

## ğŸ” Error Handling

ëª¨ë“  í•¨ìˆ˜ëŠ” ì ì ˆí•œ ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ í¬í•¨í•©ë‹ˆë‹¤:

```python
try:
    results = train_domain('medical', max_samples=1000)
except FileNotFoundError as e:
    print(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
except RuntimeError as e:
    print(f"CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±: {e}")
except Exception as e:
    print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
```

## ğŸ“ Best Practices

1. **ë©”ëª¨ë¦¬ ê´€ë¦¬**: í›ˆë ¨ í›„ í•­ìƒ `cleanup()` í˜¸ì¶œ
2. **ë„ë©”ì¸ ê²€ì¦**: í›ˆë ¨ ì „ `check_data_availability()` í™•ì¸
3. **í™˜ê²½ ê²€ì¦**: ì‹œì‘ ì „ `validate_environment()` ì‹¤í–‰
4. **ë¡œê¹…**: ì ì ˆí•œ ë¡œê¹… ì„¤ì •ìœ¼ë¡œ ì§„í–‰ ìƒí™© ì¶”ì 
5. **ì˜ˆì™¸ ì²˜ë¦¬**: ëª¨ë“  API í˜¸ì¶œì— try-catch ë¸”ë¡ ì‚¬ìš©
